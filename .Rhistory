1+1
test.array <- c("something", "test", "fiver")
test.array
char(test.array)
dim(test.array)
var(test.array)
---
title: "Course Project"
output: html_document
---
## Getting and Cleaning Data | Coursera
This is a codebook describing the variables, data, and transformations used to clean up the data.
#Data Source
Original data source: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
Original data source's description of the dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
#Data Set Information
The following is provided by the original data source:
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.
# Data Transformations
The data is processed using the run_analysis.R script, resulting in an output of a tidy data set saved ot a text file.
The transformations:
1. Merge the test and training data, subject ids and activity ids are merged into a single data set. Variables are labeld with the names provided in the features_info.txt and features.txt files.
2. Extract the mean and standard deviaion measures, keeping only those columns.
3. Add the descriptive activity names as a new column.
4. Create a tidy data set and write it out to a text file.
# Tidy data set
Variables
The tidy data set contains :
* Subject - subject identifier indicating who carried out the activity. Ranges from 1 to 30.
* Activity - an activity label indicating the type of activity: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING
* Mean of all other variables measured. This is a numeric value.
The variable name convention is like the following:
The data set is written to the 'tidydata.txt' file.
setwd("~/coursera/gettingandcleaningdata/courseproject")
---
title: "Course Project"
output: html_document
---
## Getting and Cleaning Data | Coursera
This is a codebook describing the variables, data, and transformations used to clean up the data.
#Data Source
Original data source: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
Original data source's description of the dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
#Data Set Information
The following is provided by the original data source:
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.
# Data Transformations
The data is processed using the run_analysis.R script, resulting in an output of a tidy data set saved ot a text file.
The transformations:
1. Merge the test and training data, subject ids and activity ids are merged into a single data set. Variables are labeld with the names provided in the features_info.txt and features.txt files.
2. Extract the mean and standard deviaion measures, keeping only those columns.
3. Add the descriptive activity names as a new column.
4. Create a tidy data set and write it out to a text file.
# Tidy data set
Variables
The tidy data set contains :
* Subject - subject identifier indicating who carried out the activity. Ranges from 1 to 30.
* Activity - an activity label indicating the type of activity: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING
* Mean of all other variables measured. This is a numeric value.
The variable name convention is like the following:
The data set is written to the 'tidydata.txt' file.
---
title: "Course Project"
output: html_document
---
## Getting and Cleaning Data | Coursera
This is a codebook describing the variables, data, and transformations used to clean up the data.
#Data Source
Original data source: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
Original data source's description of the dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
#Data Set Information
The following is provided by the original data source:
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.
# Data Transformations
The data is processed using the run_analysis.R script, resulting in an output of a tidy data set saved ot a text file.
The transformations:
1. Merge the test and training data, subject ids and activity ids are merged into a single data set. Variables are labeld with the names provided in the features_info.txt and features.txt files.
2. Extract the mean and standard deviaion measures, keeping only those columns.
3. Add the descriptive activity names as a new column.
4. Create a tidy data set and write it out to a text file.
# Tidy data set
Variables
The tidy data set contains :
* Subject - subject identifier indicating who carried out the activity. Ranges from 1 to 30.
* Activity - an activity label indicating the type of activity: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING
* Mean of all other variables measured. This is a numeric value.
The variable name convention is like the following:
The data set is written to the 'tidydata.txt' file.
---
title: "Course Project"
output: html_document
---
## Getting and Cleaning Data | Coursera
This is a codebook describing the variables, data, and transformations used to clean up the data.
#Data Source
Original data source: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
Original data source's description of the dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
#Data Set Information
The following is provided by the original data source:
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.
# Data Transformations
The data is processed using the run_analysis.R script, resulting in an output of a tidy data set saved ot a text file.
The transformations:
1. Merge the test and training data, subject ids and activity ids are merged into a single data set. Variables are labeld with the names provided in the features_info.txt and features.txt files.
2. Extract the mean and standard deviaion measures, keeping only those columns.
3. Add the descriptive activity names as a new column.
4. Create a tidy data set and write it out to a text file.
# Tidy data set
Variables
The tidy data set contains :
* Subject - subject identifier indicating who carried out the activity. Ranges from 1 to 30.
* Activity - an activity label indicating the type of activity: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING
* Mean of all other variables measured. This is a numeric value.
The variable name convention is like the following:
The data set is written to the 'tidydata.txt' file.
# run_analysis.R contains a script designed to merge and create a tidy data set
# from data files realted to the course project.
# Load necesesary libraries
library(dplyr)
# Step One: Merge the training and data sets to create one data set.
## Load the data sets text files containing the lables, including the activity and feature labels.
activity.labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
features.labels <- read.table("./UCI HAR Dataset/features.txt")
## Read the testing datasets, including x, y, and the subject files.
test.x <- read.table("./UCI HAR Dataset/test/X_test.txt")
test.y <- read.table("./UCI HAR Dataset/test/y_test.txt", col.names=c("Activity"))
test.subject <- read.table("./UCI HAR Dataset/test/subject_test.txt", col.names=c("Subject"))
## Read the training datasets, including x, y, and the subject files.
train.x <- read.table("./UCI HAR Dataset/train/X_train.txt")
train.y <- read.table("./UCI HAR Dataset/train/y_train.txt", col.names=c("Activity"))
train.subject <- read.table("./UCI HAR Dataset/train/subject_train.txt", col.names=c("Subject"))
## Combine the x, y, and subject data for both the testing set and the training set based on binding columns.
test <- cbind(test.subject, test.y, test.x)
train <- cbind(train.subject, train.y, train.x)
## Combine test and train, appending one on the end of the other (binding rows).
full.data <- rbind(test, train)
# Step Two: Extract measurements on mean and standard deviation for each measure.
## Move full.data set to a dplyr data frame to use dplyr functions.
activity.data <- tbl_df(full.data)
## Identify which columns contain 'mean' or 'std' (standard deviation) data by using grp
## to identify which column names includes either of those two pieces of text.
column.list <- grep("mean\\()|std\\()", features.labels$V2, ignore.case = TRUE)
column.names <- grep("mean\\()|std\\()", features.labels$V2, value=TRUE, ignore.case = TRUE)
## Increment column.list by two to add in other columns (activity and subject), then add
## those two names to column.names.
column.list <- column.list + 2
column.list <- c(1, 2, column.list)
column.names <- c("Subject", "Activity", column.names)
## Subset/select columns based on 'mean' and 'std' identifications above.
activity.data <- activity.data[, c(column.list)]
# Step Three: Assign descriptive names to the activities in the data set.
## The data from the prior step will be used to assign those column names onto the data set.
## Use data from prior step to assign those column names to the data frame.
## Need to fist convert all labels to characters
activity.data$Activity <- as.character(activity.data$Activity)
activity.labels$V1 <- as.character(activity.labels$V1)
activity.labels$V2 <- as.character(activity.labels$V2)
for(i in 1:nrow(activity.labels)) {
activity.data$Activity<-gsub(activity.labels[i,1], activity.labels[i,2], activity.data$Activity)
}
# Step Four: Appropriately label the data set with descriptive varaibel names.
## Column labels were build in a prior step, so assign those to the data frame names.
names(activity.data) <- column.names
# Step Five: Create a second, independant tidy data set using the data set above. This
# tidy data set should include the average of each variable for each activity and each subject.
## Group the data by subject and activity, and then use that set to find the mean of each.
tidy.data <- group_by(activity.data, Subject, Activity) %>% summarise_each(funs(mean))
names(tidy.data) <- column.names
## Write the tidy data set out to a text file named 'tidydate.txt'
write.table(tidy.data, "tidydata.txt", row.name=FALSE)
dim(tidy.data)
str(tidy.data)
str(tiny.data)
